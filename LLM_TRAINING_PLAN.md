# LLM训练计划：生成简短聊天内容

## 目标

训练大模型生成：
- **只返回一句话**
- **最多10个字**
- **简洁、自然、符合游戏场景**

## 当前状态

### 问题分析

从训练数据收集器收集的样本中，常见问题：

1. **输出过长**：大模型经常返回多句话或长句子
2. **冗余表达**：包含"好的，"、"我觉得，"等冗余开头
3. **过于正式**：使用"根据我的分析"等正式表达
4. **多句话**：一次返回多句话，需要人工选择第一句

### 当前处理方式

通过 `contentProcessor.ts` 进行后处理：
- 移除冗余开头和结尾
- 只选择第一句话
- 截断到最多10个字

**问题**：这是临时方案，应该让大模型直接生成符合要求的内容。

## 训练方案

### 阶段1：数据收集（当前阶段）

**目标**：收集足够的训练样本

**方法**：
1. 使用当前系统收集数据
2. 记录原始输出和处理后的输出
3. 分析常见问题和模式

**时间**：1-2周

**输出**：
- 训练数据集（原始 -> 精简后的配对）
- 问题分析报告
- 常见模式统计

### 阶段2：提示词优化

**目标**：优化 prompt，让大模型直接生成简短内容

**方法**：
1. 分析收集的数据，找出导致长输出的 prompt 模式
2. 修改 system prompt，明确要求：
   - "只返回一句话"
   - "最多10个字"
   - "简洁自然，不要冗余表达"
3. 在 prompt 中添加示例

**示例 prompt 改进**：

```
当前：
你是一个过炸扑克游戏的AI玩家，请生成一句聊天内容。

改进后：
你是一个过炸扑克游戏的AI玩家，请生成一句聊天内容。
要求：
1. 只返回一句话（不要多句）
2. 最多10个字
3. 简洁自然，不要"好的，"、"我觉得，"等冗余开头
4. 符合游戏场景，口语化

示例：
- 好牌！
- 这手不错
- 要不起
- 等等我
```

**时间**：1周

**验证**：
- 测试新 prompt 的输出长度
- 统计平均字数
- 检查是否还需要后处理

### 阶段3：Few-shot 学习

**目标**：通过示例让模型学习简短表达

**方法**：
1. 从训练数据中选择高质量样本（精简效果好、自然流畅的）
2. 在 prompt 中添加这些示例
3. 让模型学习这些示例的风格

**示例格式**：

```
示例1：
输入：玩家出牌后，手牌很好
输出：好牌！

示例2：
输入：玩家要不起
输出：要不起

示例3：
输入：玩家出大牌
输出：这手不错
```

**时间**：1-2周

**验证**：
- 对比添加示例前后的输出质量
- 统计符合要求的比例

### 阶段4：微调训练（可选）

**目标**：使用收集的数据对模型进行微调

**方法**：
1. 准备训练数据集：
   - 输入：游戏场景描述
   - 输出：简短聊天内容（10字以内）
2. 使用 LoRA 或全量微调
3. 训练专门的聊天模型

**数据集格式**：

```json
{
  "instruction": "你是一个过炸扑克游戏的AI玩家，请根据游戏场景生成一句聊天内容（最多10个字）。",
  "input": "玩家出牌后，手牌很好，当前轮次领先",
  "output": "好牌！"
}
```

**时间**：2-4周（取决于数据量和计算资源）

**验证**：
- 测试微调后的模型
- 对比微调前后的输出质量
- 统计符合要求的比例

### 阶段5：持续优化

**目标**：持续收集数据，不断改进

**方法**：
1. 定期导出训练数据
2. 分析新数据中的问题
3. 更新 prompt 或重新训练
4. 迭代改进

**时间**：持续进行

## 训练数据要求

### 数据量

- **最少**：500条高质量样本
- **推荐**：1000-2000条
- **理想**：5000+条

### 数据质量

每条数据应包含：
- 游戏场景描述（输入）
- 原始输出（大模型返回）
- 精简后输出（目标输出）
- 处理统计（长度、减少量等）

### 数据筛选标准

优先选择：
1. 精简效果好（减少50%以上）
2. 精简后自然流畅
3. 符合游戏场景
4. 口语化、简洁

## 评估指标

### 定量指标

1. **平均字数**：目标 ≤ 10字
2. **符合率**：≤ 10字的比例，目标 ≥ 90%
3. **单句率**：只包含一句话的比例，目标 ≥ 95%
4. **精简率**：平均精简百分比，目标 ≥ 30%

### 定性指标

1. **自然度**：是否自然流畅
2. **相关性**：是否贴合游戏场景
3. **多样性**：是否有足够的表达变化

## 实施步骤

### 第1周：数据收集

- [ ] 确保训练数据收集器正常工作
- [ ] 收集至少500条样本
- [ ] 分析数据，找出常见问题

### 第2周：提示词优化

- [ ] 修改 system prompt
- [ ] 添加明确的要求和示例
- [ ] 测试新 prompt 的效果

### 第3-4周：Few-shot 学习

- [ ] 选择高质量样本作为示例
- [ ] 在 prompt 中添加示例
- [ ] 测试和优化

### 第5-8周：微调训练（可选）

- [ ] 准备训练数据集
- [ ] 进行模型微调
- [ ] 测试和评估

### 持续：迭代优化

- [ ] 定期收集新数据
- [ ] 分析问题
- [ ] 持续改进

## 工具和资源

### 数据收集

- `trainingDataCollector.ts` - 自动收集训练数据
- 浏览器控制台 - 查看和导出数据

### 数据分析

- Excel/CSV - 分析训练数据
- Python脚本 - 统计分析（可选）

### 模型训练（如果进行微调）

- Ollama - 本地模型训练
- LoRA - 参数高效微调
- 训练框架 - 根据模型选择

## 预期效果

### 短期（1-2周）

- 通过提示词优化，平均字数减少到15字以内
- 符合10字要求的比例达到60%+

### 中期（1-2月）

- 通过 Few-shot 学习，平均字数减少到12字以内
- 符合10字要求的比例达到80%+

### 长期（3-6月）

- 通过微调训练，平均字数减少到10字以内
- 符合10字要求的比例达到90%+
- 基本不需要后处理

## 注意事项

1. **不要过度精简**：保持自然和流畅
2. **保持多样性**：避免所有输出都相似
3. **场景相关性**：确保内容贴合游戏场景
4. **持续监控**：定期检查输出质量

## 当前临时方案

在训练完成前，使用 `contentProcessor.ts` 进行后处理：
- 只选择第一句话
- 截断到最多10个字
- 移除冗余表达

这个方案可以保证输出符合要求，但理想情况是让大模型直接生成符合要求的内容。

