# OLLAMA 安装和配置指南

## 系统要求评估

### 你的机器配置
- **CPU**: 2核物理核心 / 4核逻辑核心
- **内存**: 8GB
- **磁盘**: 168GB 可用
- **型号**: MacBook (2015-2017)

### Qwen2.0:0.5B 模型要求
- **模型大小**: ~0.5GB (未量化)
- **运行内存**: ~2.9GB (峰值，生成 2048 tokens)
- **INT4量化后**: ~398MB
- **最低要求**: 4核 CPU、4GB 内存

## 性能评估

### ✅ 优势
1. **内存充足**: 8GB 内存完全满足要求（2.9GB 峰值）
2. **磁盘空间充足**: 168GB 可用空间足够
3. **模型小**: 0.5B 参数模型对资源要求低

### ⚠️ 潜在问题
1. **CPU 较弱**: 2核物理核心可能运行较慢
2. **无独立显卡**: MacBook 使用集成显卡，推理速度可能较慢
3. **响应时间**: 首次加载和生成可能较慢（5-15秒）

## 安装建议

### 方案1：直接安装 OLLAMA（推荐）

```bash
# 下载并安装 OLLAMA
curl -fsSL https://ollama.com/install.sh | sh

# 拉取 qwen2.0:0.5b 模型（使用量化版本，更省内存）
ollama pull qwen2.5:0.5b

# 测试运行
ollama run qwen2.5:0.5b "你好"
```

### 方案2：使用 INT4 量化版本（更省内存）

```bash
# 拉取量化版本（如果可用）
ollama pull qwen2.5:0.5b-q4_0
```

## 性能优化建议

### 1. 使用量化模型
- 使用 `q4_0` 或 `q4_1` 量化版本
- 内存占用从 2.9GB 降至 ~400MB
- 速度可能稍慢，但内存占用大幅降低

### 2. 限制并发请求
- 同时只处理一个请求
- 避免多个模型同时运行

### 3. 调整上下文长度
- 减少 `num_ctx` 参数（默认 2048）
- 可以设置为 1024 或 512 以节省内存

### 4. 使用系统资源监控
```bash
# 监控内存使用
top -l 1 | grep ollama

# 监控 CPU 使用
ps aux | grep ollama
```

## 预期性能

### 首次加载
- **时间**: 5-15 秒
- **内存**: ~2.9GB (未量化) 或 ~400MB (量化)

### 生成速度
- **CPU 模式**: 5-15 tokens/秒（2核 CPU）
- **响应时间**: 首次响应 2-5 秒，后续 0.5-2 秒/token

### 内存占用
- **运行中**: 2.9GB (峰值)
- **空闲时**: ~500MB

## 替代方案

如果 OLLAMA 运行太慢，可以考虑：

### 1. 使用在线 API
- OpenAI API
- 阿里云通义千问 API
- 百度文心一言 API

### 2. 使用更小的模型
- 如果 qwen2.5:0.5b 仍然太慢，可以考虑更小的模型

### 3. 使用云端服务
- 在更强大的服务器上运行 OLLAMA
- 通过 API 调用

## 安装步骤

```bash
# 1. 安装 OLLAMA
curl -fsSL https://ollama.com/install.sh | sh

# 2. 启动 OLLAMA 服务
ollama serve

# 3. 在另一个终端拉取模型
ollama pull qwen2.5:0.5b

# 4. 测试
ollama run qwen2.5:0.5b "你好，介绍一下你自己"
```

## 故障排查

### 如果运行太慢
1. 检查 CPU 使用率：`top -l 1 | grep ollama`
2. 检查内存使用：`ps aux | grep ollama`
3. 尝试使用量化版本：`ollama pull qwen2.5:0.5b-q4_0`

### 如果内存不足
1. 关闭其他应用程序
2. 使用量化版本
3. 减少上下文长度

## 总结

**你的机器可以运行 OLLAMA + qwen2.0:0.5b，但可能较慢。**

- ✅ **可以运行**: 内存和磁盘空间充足
- ⚠️ **可能较慢**: 2核 CPU 可能影响速度
- 💡 **建议**: 使用量化版本，限制并发，监控资源使用

如果主要用于开发测试，应该可以接受。如果用于生产环境，建议使用更强大的机器或云端服务。

