# AI Brain è®¾è®¡æ–‡æ¡£

## è®¾è®¡ç†å¿µ

### æ ¸å¿ƒåŸåˆ™

1. **æ¨¡å—åŒ–**ï¼šæ¯ä¸ªå†³ç­–ç®—æ³•éƒ½æ˜¯ç‹¬ç«‹çš„æ¨¡å—ï¼Œå¯ä»¥å•ç‹¬å¼€å‘ã€æµ‹è¯•å’Œä¼˜åŒ–
2. **å¯æ‰©å±•**ï¼šé€šè¿‡ç»Ÿä¸€æ¥å£ï¼Œéšæ—¶æ·»åŠ æ–°çš„å†³ç­–æ¨¡å—æˆ–èåˆç­–ç•¥
3. **æ™ºèƒ½èåˆ**ï¼šå¤šä¸ªæ¨¡å—çš„å»ºè®®ä¸æ˜¯ç®€å•ç›¸åŠ ï¼Œè€Œæ˜¯æ™ºèƒ½åœ°èåˆ
4. **æŒç»­è¿›åŒ–**ï¼šç³»ç»Ÿå¯ä»¥ä»æ•°æ®ä¸­å­¦ä¹ ï¼Œä¸æ–­ä¼˜åŒ–å†³ç­–è´¨é‡
5. **é«˜æ€§èƒ½**ï¼šå¼‚æ­¥æ¶æ„ã€ç¼“å­˜æœºåˆ¶ã€é™çº§ç­–ç•¥ç¡®ä¿å®æ—¶å“åº”

### æ¶æ„åˆ†å±‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           åº”ç”¨å±‚ (Game Logic)                â”‚
â”‚          æ¸¸æˆå¾ªç¯ã€UIã€ç©å®¶äº¤äº’               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         AI Brain Core (å†³ç­–ä¸­æ¢)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      Cognitive Layer (è®¤çŸ¥å±‚)        â”‚   â”‚
â”‚  â”‚      - å±€é¢ç†è§£                       â”‚   â”‚
â”‚  â”‚      - æˆ˜ç•¥åˆ¤æ–­                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                   â†“                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Fusion Layer (å†³ç­–èåˆå±‚)          â”‚   â”‚
â”‚  â”‚   - å¤šæºå†³ç­–æ•´åˆ                      â”‚   â”‚
â”‚  â”‚   - åŠ¨æ€æƒé‡è°ƒæ•´                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MCTS   â”‚          â”‚  LLM   â”‚    ...æ›´å¤šæ¨¡å—
â”‚ æ¨¡å—   â”‚          â”‚  æ¨¡å—  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## å…³é”®ç»„ä»¶è®¾è®¡

### 1. Decision Module (å†³ç­–æ¨¡å—)

**æ¥å£å®šä¹‰ï¼š** `IDecisionModule`

**æ ¸å¿ƒæ–¹æ³•ï¼š**
- `analyze()`: åˆ†æå±€é¢ï¼Œè¿”å›å®Œæ•´åˆ†æç»“æœ
- `suggest()`: ç»™å‡ºåŠ¨ä½œå»ºè®®
- `evaluate()`: è¯„ä¼°æŸä¸ªåŠ¨ä½œçš„è´¨é‡
- `explain()`: è§£é‡Šå†³ç­–æ¨ç†è¿‡ç¨‹
- `isApplicable()`: åˆ¤æ–­æ˜¯å¦é€‚ç”¨å½“å‰å±€é¢
- `getRecommendedWeight()`: å»ºè®®è‡ªå·±çš„æƒé‡

**è®¾è®¡ç‰¹ç‚¹ï¼š**
- ç»Ÿä¸€æ¥å£ç¡®ä¿æ‰€æœ‰æ¨¡å—å¯äº’æ¢
- æ¯ä¸ªæ¨¡å—ç‹¬ç«‹è´Ÿè´£ä¸€ç§å†³ç­–ç®—æ³•
- æ¨¡å—å¯ä»¥è‡ªå·±å»ºè®®æƒé‡ï¼ˆè‡ªé€‚åº”ï¼‰
- æ”¯æŒå¯é€‰çš„å­¦ä¹ åŠŸèƒ½ `learn()`

**æ‰©å±•ç‚¹ï¼š**
```typescript
// æ·»åŠ æ–°æ¨¡å—åªéœ€3æ­¥ï¼š

// 1. ç»§æ‰¿åŸºç±»
class NewModule extends BaseDecisionModule {
  readonly name = 'new_module';
  
  // 2. å®ç°æ ¸å¿ƒæ–¹æ³•
  protected async performAnalysis(state: GameState) {
    // ä½ çš„ç®—æ³•
  }
  
  protected async performExplanation(state, action) {
    // è§£é‡Šé€»è¾‘
  }
}

// 3. æ³¨å†Œ
brain.registerModule('new_module', new NewModule());
```

### 2. Fusion Layer (èåˆå±‚)

**èŒè´£ï¼š**
- æ”¶é›†æ‰€æœ‰æ¨¡å—çš„å»ºè®®
- æ ¹æ®é…ç½®å’Œå±€é¢åŠ¨æ€è°ƒæ•´æƒé‡
- é€‰æ‹©æœ€ç»ˆå†³ç­–
- ç”Ÿæˆç»¼åˆæ¨ç†è¯´æ˜

**èåˆç­–ç•¥ï¼š**

1. **åŠ æƒå¹³å‡ (Weighted Average)**
   - æ ¹æ®æ¨¡å—æƒé‡å’Œç½®ä¿¡åº¦åŠ æƒ
   - é€‚åˆå„æ¨¡å—äº’è¡¥çš„æƒ…å†µ

2. **æŠ•ç¥¨ (Voting)**
   - ç»Ÿè®¡å„æ¨¡å—çš„å»ºè®®ï¼Œå–å¤šæ•°
   - é€‚åˆæ¨¡å—å»ºè®®åˆ†æ­§å¤§çš„æƒ…å†µ

3. **çº§è” (Cascade)**
   - æŒ‰ä¼˜å…ˆçº§ä¾æ¬¡é€‰æ‹©
   - é€‚åˆæœ‰æ˜ç¡®ä¸»æ¬¡å…³ç³»çš„æƒ…å†µ

4. **è‡ªé€‚åº” (Adaptive)**
   - æ ¹æ®å±€é¢å¤æ‚åº¦åŠ¨æ€é€‰æ‹©ç­–ç•¥
   - æœ€æ™ºèƒ½ä½†è®¡ç®—å¼€é”€ç¨å¤§

**æƒé‡åŠ¨æ€è°ƒæ•´ï¼š**
```typescript
// æƒé‡è§„åˆ™ç³»ç»Ÿ
{
  llm: {
    baseWeight: 0.5,
    weightRules: [
      {
        condition: 'complex_situation',  // å¤æ‚å±€é¢
        weight: 0.7  // æé«˜LLMæƒé‡
      },
      {
        condition: 'critical',  // å…³é”®æ—¶åˆ»
        weight: 0.3  // é™ä½LLMæƒé‡ï¼ˆä¸å¤Ÿç¨³å®šï¼‰
      },
      {
        condition: (state) => state.myHand.length > 10,
        weight: 0.6  // è‡ªå®šä¹‰æ¡ä»¶
      }
    ]
  }
}
```

### 3. Context Manager (ä¸Šä¸‹æ–‡ç®¡ç†)

**èŒè´£ï¼š**
- ç»´æŠ¤æ¸¸æˆå†å²
- è®°å½•å†³ç­–å†å²
- ç”Ÿæˆè®­ç»ƒæ•°æ®
- æä¾›ä¸Šä¸‹æ–‡ä¿¡æ¯ç»™å†³ç­–æ¨¡å—

**æ•°æ®æµï¼š**
```
æ¸¸æˆè¿›è¡Œ â†’ æ›´æ–°çŠ¶æ€ â†’ åšå†³ç­– â†’ è®°å½•å†³ç­– â†’ æ‰§è¡ŒåŠ¨ä½œ â†’ è®°å½•ç»“æœ
    â†‘                                                      â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç”¨äºå­¦ä¹ å’Œåˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Cognitive Layer (è®¤çŸ¥å±‚)

**èŒè´£ï¼š**
- é«˜å±‚æ¬¡çš„å±€é¢ç†è§£
- æˆ˜ç•¥æ„å›¾åˆ¤æ–­
- è¯†åˆ«å¨èƒå’Œæœºä¼š
- å›¢é˜Ÿåä½œåˆ†æï¼ˆå›¢é˜Ÿæ¨¡å¼ï¼‰

**è¾“å‡ºï¼š**
- æ‰‹ç‰Œå¼ºåº¦è¯„ä¼°
- èƒœç‡ä¼°è®¡
- æˆ˜ç•¥æ„å›¾ï¼ˆè¿›æ”»/é˜²å®ˆ/é…åˆç­‰ï¼‰
- æ¨èæ‰“æ³•é£æ ¼
- å…³é”®å› ç´ åˆ—è¡¨

**è®¾è®¡æ„å›¾ï¼š**
è®¤çŸ¥å±‚æä¾›"äººç±»è§†è§’"çš„å±€é¢ç†è§£ï¼Œå¸®åŠ©æ¨¡å—åšå‡ºæ›´ç¬¦åˆç›´è§‰çš„å†³ç­–ã€‚

## æ‰©å±•ç‚¹è®¾è®¡

### 1. æ–°å†³ç­–æ¨¡å—

**æ‰©å±•éš¾åº¦ï¼š** â­ (ç®€å•)

**æ­¥éª¤ï¼š**
1. ç»§æ‰¿ `BaseDecisionModule`
2. å®ç° `performAnalysis()` å’Œ `performExplanation()`
3. å¯é€‰å®ç° `learn()` æ”¯æŒåœ¨çº¿å­¦ä¹ 
4. æ³¨å†Œåˆ°Brain

**ç¤ºä¾‹ï¼š**
```typescript
class ReinforcementLearningModule extends BaseDecisionModule {
  private model: RLModel;
  
  protected async performAnalysis(state: GameState) {
    const action = this.model.predict(state);
    return {
      analysis: {...},
      suggestions: [{ action, score: 0.8, confidence: 0.9, reasoning: 'RLæ¨¡å‹é¢„æµ‹' }],
      confidence: 0.9,
      reasoning: 'å¼ºåŒ–å­¦ä¹ æ¨¡å‹',
      computeTime: 0
    };
  }
  
  async learn(samples: LearningSample[]) {
    // åœ¨çº¿å­¦ä¹ 
    await this.model.update(samples);
  }
}
```

### 2. æ–°èåˆç­–ç•¥

**æ‰©å±•éš¾åº¦ï¼š** â­â­ (ä¸­ç­‰)

**æ­¥éª¤ï¼š**
1. åœ¨ `FusionLayer` ä¸­æ·»åŠ æ–°ç­–ç•¥æ–¹æ³•
2. åœ¨é…ç½®ä¸­æ”¯æŒæ–°ç­–ç•¥åç§°

**ç¤ºä¾‹ï¼š**
```typescript
// åœ¨FusionLayerä¸­æ·»åŠ 
private expertSystemFusion(sources: DecisionSource[]) {
  // ä¸“å®¶ç³»ç»Ÿèåˆï¼šåŸºäºè§„åˆ™é€‰æ‹©
  const rules = [
    { condition: (s) => s.moduleName === 'mcts' && s.confidence > 0.9, priority: 1 },
    { condition: (s) => s.moduleName === 'llm' && s.confidence > 0.8, priority: 2 }
  ];
  
  // åº”ç”¨è§„åˆ™é€‰æ‹©æœ€ä½³å»ºè®®
  // ...
}
```

### 3. LLMé›†æˆ

**æ‰©å±•éš¾åº¦ï¼š** â­â­â­ (è¾ƒå¤æ‚)

**éœ€è¦å®ç°ï¼š**

1. **LLMå®¢æˆ·ç«¯æŠ½è±¡**
```typescript
interface ILLMClient {
  complete(prompt: string): Promise<string>;
  embed(text: string): Promise<number[]>;
}
```

2. **Promptå·¥ç¨‹**
```typescript
class PromptManager {
  buildDecisionPrompt(state: GameState): string {
    // å°†æ¸¸æˆçŠ¶æ€è½¬æ¢ä¸ºLLMå‹å¥½çš„æç¤ºè¯
    return formatStateForLLM(state) + '\nè¯·åˆ†æå±€é¢å¹¶å»ºè®®å‡ºç‰Œã€‚';
  }
  
  parseResponse(response: string): ActionSuggestion {
    // è§£æLLMçš„å“åº”
  }
}
```

3. **LLMå†³ç­–æ¨¡å—**
```typescript
class LLMDecisionModule extends BaseDecisionModule {
  private client: ILLMClient;
  private promptManager: PromptManager;
  
  protected async performAnalysis(state: GameState) {
    const prompt = this.promptManager.buildDecisionPrompt(state);
    const response = await this.client.complete(prompt);
    const suggestion = this.promptManager.parseResponse(response);
    
    return {
      analysis: {...},
      suggestions: [suggestion],
      confidence: 0.7,
      reasoning: response,
      computeTime: 0
    };
  }
}
```

**ä¼˜åŒ–è€ƒè™‘ï¼š**
- å¼‚æ­¥è°ƒç”¨ï¼Œä¸é˜»å¡æ¸¸æˆ
- ç¼“å­˜ç›¸ä¼¼å±€é¢çš„å“åº”
- è¶…æ—¶å’Œé™çº§ç­–ç•¥
- å“åº”è´¨é‡è¯„ä¼°

### 4. è®­ç»ƒç³»ç»Ÿ

**æ‰©å±•éš¾åº¦ï¼š** â­â­â­â­ (å¤æ‚)

**ç»„ä»¶ï¼š**

1. **æ•°æ®ç”Ÿæˆå™¨**
```typescript
class TrainingDataGenerator {
  // ä»è‡ªæˆ‘å¯¹å¼ˆç”Ÿæˆæ•°æ®
  async generateSelfPlayData(numGames: number): Promise<TrainingSample[]>;
  
  // ä»ä¸“å®¶å¯¹å±€ç”Ÿæˆæ•°æ®
  async generateExpertData(games: Game[]): Promise<TrainingSample[]>;
  
  // æ•°æ®å¢å¼º
  augmentData(samples: TrainingSample[]): TrainingSample[];
}
```

2. **æ ‡æ³¨å™¨**
```typescript
class DataAnnotator {
  // ç”¨MCTSæ ‡æ³¨å†³ç­–è´¨é‡
  async annotateBest action(sample: TrainingSample): Promise<TrainingSample>;
  
  // ç”¨ä¸“å®¶çŸ¥è¯†æ ‡æ³¨
  async annotateWithExpert(sample: TrainingSample): Promise<TrainingSample>;
}
```

3. **è®­ç»ƒå™¨**
```typescript
class ModelTrainer {
  // ç›‘ç£å­¦ä¹ 
  async supervisedTrain(samples: TrainingSample[]): Promise<void>;
  
  // å¼ºåŒ–å­¦ä¹ 
  async reinforcementTrain(rewardFunction: RewardFunction): Promise<void>;
  
  // åœ¨çº¿å­¦ä¹ 
  async onlineTrain(recentSamples: TrainingSample[]): Promise<void>;
}
```

### 5. é€šä¿¡ç³»ç»Ÿ

**æ‰©å±•éš¾åº¦ï¼š** â­â­â­ (è¾ƒå¤æ‚)

**ç»„ä»¶ï¼š**

1. **æˆ˜æœ¯é€šä¿¡**
```typescript
class TacticalCommunication {
  // ç”Ÿæˆæˆ˜æœ¯ä¿¡å·
  generateSignal(intent: TacticalIntent): CommunicationMessage;
  
  // è§£æé˜Ÿå‹ä¿¡å·
  parseSignal(message: CommunicationMessage): TacticalInfo;
}
```

2. **ç¤¾äº¤èŠå¤©**
```typescript
class SocialCommunication {
  // ç”ŸæˆèŠå¤©æ¶ˆæ¯ï¼ˆåŸºäºLLMï¼‰
  async generateChat(
    context: GameState,
    personality: PersonalityConfig,
    emotion: Emotion
  ): Promise<CommunicationMessage>;
}
```

## æ€§èƒ½ä¼˜åŒ–

### 1. ç¼“å­˜æœºåˆ¶

```typescript
class DecisionCache {
  private cache: LRUCache<string, Decision>;
  
  get(state: GameState): Decision | null {
    const key = this.stateToKey(state);
    return this.cache.get(key) || null;
  }
  
  set(state: GameState, decision: Decision): void {
    const key = this.stateToKey(state);
    this.cache.set(key, decision);
  }
}
```

### 2. é¢„åˆ¤ç³»ç»Ÿ

```typescript
class PredictionSystem {
  // åœ¨å¯¹æ‰‹æ€è€ƒæ—¶é¢„å…ˆåˆ†æå¯èƒ½çš„å±€é¢
  async predictNextStates(currentState: GameState): Promise<Map<string, Decision>> {
    const possibleActions = this.enumeratePossibleActions(currentState);
    const predictions = new Map();
    
    for (const action of possibleActions) {
      const nextState = this.simulate(currentState, action);
      const decision = await this.brain.makeDecision(nextState);
      predictions.set(this.stateToKey(nextState), decision);
    }
    
    return predictions;
  }
}
```

### 3. å¼‚æ­¥æ¶æ„

```typescript
// æ‰€æœ‰è€—æ—¶æ“ä½œéƒ½æ˜¯å¼‚æ­¥çš„
async makeDecision(state: GameState): Promise<Decision> {
  // å¹¶è¡Œè°ƒç”¨æ‰€æœ‰æ¨¡å—
  const moduleTasks = this.modules.map(m => m.analyze(state));
  const results = await Promise.all(moduleTasks);
  
  // èåˆå†³ç­–
  return this.fuse(results);
}
```

## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

```typescript
describe('MCTSDecisionModule', () => {
  it('should suggest valid actions', async () => {
    const module = new MCTSDecisionModule();
    await module.initialize({ enabled: true, baseWeight: 0.8 });
    
    const result = await module.analyze(testGameState);
    
    expect(result.suggestions).toHaveLength(greaterThan(0));
    expect(result.confidence).toBeGreaterThan(0);
  });
});
```

### 2. é›†æˆæµ‹è¯•

```typescript
describe('AIBrain', () => {
  it('should fuse multiple module suggestions', async () => {
    const brain = new AIBrain();
    brain.registerModule('mcts', new MCTSModule());
    brain.registerModule('rule', new RuleModule());
    await brain.initialize();
    
    const decision = await brain.makeDecision(testState);
    
    expect(decision.sources).toHaveLength(2);
    expect(decision.fusionMethod).toBeDefined();
  });
});
```

### 3. è‡ªæˆ‘å¯¹å¼ˆæµ‹è¯•

```typescript
async function selfPlayTest() {
  const brain1 = new AIBrain({ personality: { preset: 'aggressive' } });
  const brain2 = new AIBrain({ personality: { preset: 'conservative' } });
  
  const results = await runGames(brain1, brain2, 1000);
  
  // è¯„ä¼°èƒœç‡ã€å†³ç­–è´¨é‡ç­‰
  expect(results.brain1WinRate).toBeCloseTo(0.5, 0.1);
}
```

## æœªæ¥æ‰©å±•æ–¹å‘

### çŸ­æœŸ (1-3ä¸ªæœˆ)

1. **å®Œå–„LLMé›†æˆ**
   - å®ç°æœ¬åœ°æ¨¡å‹å®¢æˆ·ç«¯
   - Promptä¼˜åŒ–
   - å“åº”è§£æ

2. **è®­ç»ƒç³»ç»Ÿ**
   - æ•°æ®æ”¶é›†ç®¡é“
   - æ ‡æ³¨å·¥å…·
   - åŸºç¡€è®­ç»ƒ

3. **é€šä¿¡ç³»ç»Ÿ**
   - æˆ˜æœ¯ä¿¡å·
   - åŸºç¡€èŠå¤©

### ä¸­æœŸ (3-6ä¸ªæœˆ)

1. **å¼ºåŒ–å­¦ä¹ **
   - è‡ªæˆ‘å¯¹å¼ˆ
   - å¥–åŠ±å‡½æ•°è®¾è®¡
   - PPO/DQNç®—æ³•

2. **åœ¨çº¿å­¦ä¹ **
   - å¢é‡æ›´æ–°
   - A/Bæµ‹è¯•
   - æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

3. **é«˜çº§é€šä¿¡**
   - LLMç”Ÿæˆè‡ªç„¶è¯­è¨€
   - æƒ…æ„Ÿè¡¨è¾¾
   - ä¸ªæ€§åŒ–

### é•¿æœŸ (6ä¸ªæœˆ+)

1. **æŒç»­è¿›åŒ–**
   - è‡ªåŠ¨å‘ç°å¼±ç‚¹
   - è‡ªåŠ¨ç”Ÿæˆä¿®å¤
   - è‡ªä¸»ä¼˜åŒ–

2. **å¤šæ™ºèƒ½ä½“**
   - å›¢é˜Ÿåä½œå­¦ä¹ 
   - å¯¹æ‰‹å»ºæ¨¡
   - å…ƒç­–ç•¥

3. **é€šç”¨åŒ–**
   - é€‚é…å…¶ä»–æ‰‘å…‹æ¸¸æˆ
   - é€‚é…å…¶ä»–å¡ç‰Œæ¸¸æˆ
   - AIæ¡†æ¶é€šç”¨åŒ–

## æ€»ç»“

AI Brainæ˜¯ä¸€ä¸ª**æ¨¡å—åŒ–ã€å¯æ‰©å±•ã€æ™ºèƒ½èåˆ**çš„AIå†³ç­–æ¡†æ¶ã€‚

**æ ¸å¿ƒä¼˜åŠ¿ï¼š**
- âœ… ç»Ÿä¸€æ¥å£ï¼Œæ˜“äºæ‰©å±•
- âœ… æ™ºèƒ½èåˆï¼Œå‘æŒ¥å„ç®—æ³•ä¼˜åŠ¿
- âœ… æŒç»­å­¦ä¹ ï¼Œä¸æ–­è¿›åŒ–
- âœ… é«˜æ€§èƒ½ï¼Œå®æ—¶å“åº”
- âœ… å¯è§£é‡Šï¼Œä¾¿äºè°ƒè¯•

**æ‰©å±•æ€§è®¾è®¡ï¼š**
- ğŸ”Œ æ’ä»¶å¼æ¨¡å—ç³»ç»Ÿ
- âš™ï¸ çµæ´»çš„é…ç½®ç®¡ç†
- ğŸ“Š å®Œå–„çš„æ•°æ®æ”¶é›†
- ğŸ”„ æŒç»­å­¦ä¹ æœºåˆ¶
- ğŸ¯ å¤šç§èåˆç­–ç•¥

è¿™ä¸ªæ¡†æ¶ä¸ºå®ç°"AIä¸“å®¶+AIç¤¾äº¤"çš„æ„¿æ™¯æ‰“ä¸‹äº†åšå®åŸºç¡€ï¼

