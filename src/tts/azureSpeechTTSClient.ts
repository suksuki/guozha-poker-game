/**
 * Azure Speech Service TTS å®¢æˆ·ç«¯
 * ä½¿ç”¨ Azure Cognitive Services Speech API
 * 
 * Azure Speech Service æ˜¯ä¸€ä¸ªå¼ºå¤§çš„äº‘ç«¯ TTS æœåŠ¡ï¼Œç‰¹ç‚¹ï¼š
 * - æ”¯æŒ 140+ ç§è¯­è¨€å’Œæ–¹è¨€
 * - 400+ ç§ç¥ç»ç½‘ç»œè¯­éŸ³
 * - é«˜è´¨é‡è¯­éŸ³åˆæˆ
 * - æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰å¤šç§è¯­è¨€
 * 
 * é…ç½®æŒ‡å—ï¼š
 * 1. åœ¨ Azure Portal åˆ›å»º Speech Service èµ„æº
 * 2. è·å– Subscription Key å’Œ Region
 * 3. è®¾ç½®ç¯å¢ƒå˜é‡ VITE_AZURE_SPEECH_KEY å’Œ VITE_AZURE_SPEECH_REGION
 * 
 * æ–‡æ¡£ï¼šhttps://learn.microsoft.com/azure/ai-services/speech-service/
 */

import { type ITTSClient, type TTSOptions, type TTSResult, type TTSLanguage } from './ttsClient';
import { VoiceConfig } from '../types/card';
import { getAudioCache } from './audioCache';

export interface AzureSpeechTTSConfig {
  subscriptionKey?: string;  // Azure Speech Service Subscription Key
  region?: string;  // Azure åŒºåŸŸï¼Œå¦‚ 'eastus', 'westus2' ç­‰
  voiceName?: string;  // è¯­éŸ³åç§°ï¼Œé»˜è®¤æ ¹æ®è¯­è¨€è‡ªåŠ¨é€‰æ‹©
  timeout?: number;  // è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤ 30000
  retryCount?: number;  // é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ 2
}

/**
 * Azure Speech Service TTS å®¢æˆ·ç«¯å®ç°
 */
export class AzureSpeechTTSClient implements ITTSClient {
  private subscriptionKey: string | null;
  private region: string;
  private baseUrl: string;
  private timeout: number;
  private retryCount: number;
  private config: AzureSpeechTTSConfig;
  private audioCache = getAudioCache();

  constructor(config: AzureSpeechTTSConfig = {}) {
    // ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®ä¸­è·å– Subscription Key
    this.subscriptionKey = config.subscriptionKey || 
                          (import.meta.env?.VITE_AZURE_SPEECH_KEY as string | undefined) ||
                          (typeof window !== 'undefined' && (window as any).AZURE_SPEECH_KEY) ||
                          null;
    
    // ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®ä¸­è·å– Region
    this.region = config.region || 
                  (import.meta.env?.VITE_AZURE_SPEECH_REGION as string | undefined) ||
                  (typeof window !== 'undefined' && (window as any).AZURE_SPEECH_REGION) ||
                  'eastus';  // é»˜è®¤åŒºåŸŸ
    
    this.timeout = config.timeout || 30000;
    this.retryCount = config.retryCount || 2;
    this.config = {
      voiceName: config.voiceName,  // å¦‚æœæœªæŒ‡å®šï¼Œå°†æ ¹æ®è¯­è¨€è‡ªåŠ¨é€‰æ‹©
    };

    // æ„å»º API ç«¯ç‚¹ URL
    this.baseUrl = `https://${this.region}.tts.speech.microsoft.com/cognitiveservices/v1`;

    if (!this.subscriptionKey) {
    } else {
    }
  }

  async synthesize(text: string, options: TTSOptions = {}): Promise<TTSResult> {
    if (!this.subscriptionKey) {
      throw new Error('Azure Speech Service Subscription Key æœªé…ç½®');
    }

    const { useCache = true, lang = 'zh', voiceConfig } = options;

    // ç”Ÿæˆç¼“å­˜é”®
    const cacheKey = this.getCacheKey(text, lang, voiceConfig);

    // æ£€æŸ¥ç¼“å­˜
    if (useCache) {
      const cached = await this.audioCache.get(cacheKey);
      if (cached) {
        return cached;
      }
    }

    // è°ƒç”¨ Azure Speech Service API
    let lastError: Error | null = null;
    for (let i = 0; i <= this.retryCount; i++) {
      try {
        const result = await this.callAzureSpeechTTS(text, lang, voiceConfig);

        // ä¿å­˜åˆ°ç¼“å­˜
        if (useCache && result) {
          await this.audioCache.set(cacheKey, result);
        }

        return result;
      } catch (error) {
        lastError = error instanceof Error ? error : new Error(String(error));
        if (i < this.retryCount) {
          // ç­‰å¾…åé‡è¯•
          await new Promise((resolve) => setTimeout(resolve, 1000 * (i + 1)));
        }
      }
    }

    throw lastError || new Error('Azure Speech Service API è°ƒç”¨å¤±è´¥');
  }

  /**
   * è°ƒç”¨ Azure Speech Service TTS API
   */
  private async callAzureSpeechTTS(
    text: string,
    lang: TTSLanguage,
    voiceConfig?: VoiceConfig
  ): Promise<TTSResult> {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), this.timeout);

    try {
      // æ˜ å°„è¯­è¨€ä»£ç åˆ° Azure è¯­éŸ³æœåŠ¡æ ¼å¼
      const languageCode = this.mapLanguage(lang);
      
      // é€‰æ‹©è¯­éŸ³åç§°ï¼ˆæ ¹æ® gender æˆ–ä½¿ç”¨é»˜è®¤ï¼‰
      let voiceName = this.config.voiceName;
      if (!voiceName) {
        voiceName = this.selectVoiceByLanguage(languageCode, voiceConfig?.gender);
      }

      // æ„å»º SSMLï¼ˆSpeech Synthesis Markup Languageï¼‰
      const ssml = this.buildSSML(text, voiceName, languageCode, voiceConfig);


      const response = await fetch(this.baseUrl, {
        method: 'POST',
        headers: {
          'Ocp-Apim-Subscription-Key': this.subscriptionKey!,
          'Content-Type': 'application/ssml+xml',
          'X-Microsoft-OutputFormat': 'audio-24khz-48kbitrate-mono-mp3',  // MP3 æ ¼å¼
        },
        body: ssml,
        signal: controller.signal,
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        const errorText = await response.text();
        let errorMessage = `Azure Speech Service API é”™è¯¯: ${response.status} ${response.statusText}`;
        
        try {
          // Azure å¯èƒ½è¿”å› XML æ ¼å¼çš„é”™è¯¯
          if (errorText.includes('<')) {
            const parser = new DOMParser();
            const xmlDoc = parser.parseFromString(errorText, 'text/xml');
            const errorElement = xmlDoc.querySelector('Message') || xmlDoc.querySelector('message');
            if (errorElement) {
              errorMessage += `\né”™è¯¯æ¶ˆæ¯: ${errorElement.textContent}`;
            }
          } else {
            errorMessage += ` - ${errorText}`;
          }
        } catch {
          errorMessage += ` - ${errorText}`;
        }
        
        // å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œæä¾›æ›´è¯¦ç»†çš„æç¤º
        if (response.status === 401 || response.status === 403) {
          errorMessage += '\n\nğŸ’¡ å¯èƒ½çš„åŸå› ï¼š';
          errorMessage += '\n1. Subscription Key æ— æ•ˆæˆ–å·²è¿‡æœŸ';
          errorMessage += '\n2. Region é…ç½®é”™è¯¯';
          errorMessage += '\n3. è¯·æ£€æŸ¥ Azure Portal ä¸­çš„å¯†é’¥å’ŒåŒºåŸŸè®¾ç½®';
        }
        
        throw new Error(errorMessage);
      }

      // Azure Speech Service ç›´æ¥è¿”å›éŸ³é¢‘æ•°æ®ï¼ˆäºŒè¿›åˆ¶ï¼‰
      const audioData = await response.arrayBuffer();
      
      if (!audioData || audioData.byteLength === 0) {
        throw new Error('Azure Speech Service API è¿”å›ç©ºéŸ³é¢‘æ•°æ®');
      }

      // ä¼°ç®—éŸ³é¢‘æ—¶é•¿
      const duration = this.estimateDuration(text, voiceConfig?.rate || 1.0);

      return {
        audioBuffer: audioData,
        duration,
        format: 'audio/mpeg',  // MP3 æ ¼å¼
      };
    } catch (error) {
      clearTimeout(timeoutId);
      if (error instanceof Error && error.name === 'AbortError') {
        throw new Error(`Azure Speech Service API è¯·æ±‚è¶…æ—¶ (${this.timeout}ms)`);
      }
      throw error;
    }
  }

  /**
   * æ„å»º SSMLï¼ˆSpeech Synthesis Markup Languageï¼‰
   */
  private buildSSML(
    text: string,
    voiceName: string,
    languageCode: string,
    voiceConfig?: VoiceConfig
  ): string {
    // è½¬ä¹‰ XML ç‰¹æ®Šå­—ç¬¦
    const escapedText = text
      .replace(/&/g, '&amp;')
      .replace(/</g, '&lt;')
      .replace(/>/g, '&gt;')
      .replace(/"/g, '&quot;')
      .replace(/'/g, '&apos;');

    // è®¡ç®—è¯­é€Ÿï¼ˆAzure ä½¿ç”¨ç›¸å¯¹å€¼ï¼Œ1.0 ä¸ºæ­£å¸¸é€Ÿåº¦ï¼‰
    const rate = voiceConfig?.rate || 1.0;
    const ratePercent = Math.round((rate - 1.0) * 100);  // è½¬æ¢ä¸ºç™¾åˆ†æ¯”åç§»
    const rateValue = ratePercent >= 0 ? `+${ratePercent}%` : `${ratePercent}%`;

    // è®¡ç®—éŸ³è°ƒï¼ˆAzure ä½¿ç”¨ç›¸å¯¹å€¼ï¼Œ+0st ä¸ºæ­£å¸¸éŸ³è°ƒï¼‰
    const pitch = voiceConfig?.pitch || 0.0;
    const pitchValue = pitch >= 0 ? `+${pitch.toFixed(1)}st` : `${pitch.toFixed(1)}st`;

    // è®¡ç®—éŸ³é‡ï¼ˆAzure ä½¿ç”¨ç›¸å¯¹å€¼ï¼Œ+0% ä¸ºæ­£å¸¸éŸ³é‡ï¼‰
    const volume = voiceConfig?.volume || 1.0;
    const volumePercent = Math.round((volume - 1.0) * 100);
    const volumeValue = volumePercent >= 0 ? `+${volumePercent}%` : `${volumePercent}%`;

    // æ„å»º SSML
    const ssml = `<?xml version="1.0" encoding="UTF-8"?>
<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="${languageCode}">
  <voice name="${voiceName}">
    <prosody rate="${rateValue}" pitch="${pitchValue}" volume="${volumeValue}">
      ${escapedText}
    </prosody>
  </voice>
</speak>`;

    return ssml;
  }

  /**
   * æ£€æŸ¥ Azure Speech Service æ˜¯å¦å¯ç”¨
   */
  async checkHealth(): Promise<boolean> {
    if (!this.subscriptionKey) {
      return false;
    }

    try {
      // ä½¿ç”¨ä¸€ä¸ªç®€çŸ­çš„æµ‹è¯•è¯·æ±‚
      const testText = 'test';
      const languageCode = 'en-US';
      const voiceName = 'en-US-JennyNeural';

      const ssml = this.buildSSML(testText, voiceName, languageCode);

      const response = await fetch(this.baseUrl, {
        method: 'POST',
        headers: {
          'Ocp-Apim-Subscription-Key': this.subscriptionKey,
          'Content-Type': 'application/ssml+xml',
          'X-Microsoft-OutputFormat': 'audio-24khz-48kbitrate-mono-mp3',
        },
        body: ssml,
        signal: AbortSignal.timeout(5000),
      });

      // æ£€æŸ¥å“åº”çŠ¶æ€
      if (response.status === 401 || response.status === 403) {
        return false;
      }
      
      // å¦‚æœè¿”å› 200 ä¸”æœ‰éŸ³é¢‘æ•°æ®ï¼Œè®¤ä¸ºæœåŠ¡å¯ç”¨
      if (response.ok) {
        const audioData = await response.arrayBuffer();
        return audioData.byteLength > 0;
      }
      
      return false;
    } catch (error) {
      return false;
    }
  }

  /**
   * æ˜ å°„è¯­è¨€ä»£ç åˆ° Azure è¯­éŸ³æœåŠ¡æ ¼å¼
   */
  private mapLanguage(lang: TTSLanguage): string {
    const langMap: Record<TTSLanguage, string> = {
      'zh': 'zh-CN',  // ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰
      'ja': 'ja-JP',  // æ—¥è¯­
      'ko': 'ko-KR',  // éŸ©è¯­
      'nanchang': 'zh-CN',  // å—æ˜Œè¯æš‚æ—¶ä½¿ç”¨ä¸­æ–‡
    };
    return langMap[lang] || 'zh-CN';
  }

  /**
   * æ ¹æ®è¯­è¨€å’Œæ€§åˆ«é€‰æ‹©è¯­éŸ³
   */
  private selectVoiceByLanguage(languageCode: string, gender?: 'male' | 'female'): string {
    // å¦‚æœé…ç½®ä¸­æŒ‡å®šäº†è¯­éŸ³åç§°ï¼Œä¼˜å…ˆä½¿ç”¨
    if (this.config.voiceName) {
      return this.config.voiceName;
    }

    // Azure Speech Service è¯­éŸ³åç§°æ˜ å°„
    const voiceMap: Record<string, { male: string; female: string }> = {
      'zh-CN': {
        male: 'zh-CN-YunxiNeural',  // ä¸­æ–‡ç”·å£°ï¼ˆå¹´è½»ï¼‰
        female: 'zh-CN-XiaoxiaoNeural',  // ä¸­æ–‡å¥³å£°ï¼ˆå¹´è½»ï¼Œæ¨èï¼‰
      },
      'en-US': {
        male: 'en-US-GuyNeural',
        female: 'en-US-JennyNeural',
      },
      'ja-JP': {
        male: 'ja-JP-KeitaNeural',
        female: 'ja-JP-NanamiNeural',
      },
      'ko-KR': {
        male: 'ko-KR-InJoonNeural',
        female: 'ko-KR-SunHiNeural',
      },
    };

    const voices = voiceMap[languageCode] || voiceMap['zh-CN'];
    return gender === 'male' ? voices.male : voices.female;
  }

  /**
   * è·å–å¯ç”¨çš„ä¸­æ–‡è¯­éŸ³åˆ—è¡¨
   */
  static getAvailableChineseVoices(): Array<{ name: string; displayName: string; gender: string; style?: string }> {
    return [
      { name: 'zh-CN-XiaoxiaoNeural', displayName: 'æ™“æ™“ï¼ˆå¥³ï¼Œå¹´è½»æ´»æ³¼ï¼‰', gender: 'å¥³', style: 'å¹´è½»æ´»æ³¼' },
      { name: 'zh-CN-YunxiNeural', displayName: 'äº‘å¸Œï¼ˆç”·ï¼Œå¹´è½»ï¼‰', gender: 'ç”·', style: 'å¹´è½»' },
      { name: 'zh-CN-YunyangNeural', displayName: 'äº‘æ‰¬ï¼ˆç”·ï¼Œæˆç†Ÿï¼‰', gender: 'ç”·', style: 'æˆç†Ÿ' },
      { name: 'zh-CN-XiaoyiNeural', displayName: 'æ™“ä¼Šï¼ˆå¥³ï¼Œæ¸©æŸ”ï¼‰', gender: 'å¥³', style: 'æ¸©æŸ”' },
      { name: 'zh-CN-YunjianNeural', displayName: 'äº‘å¥ï¼ˆç”·ï¼Œæˆç†Ÿç¨³é‡ï¼‰', gender: 'ç”·', style: 'æˆç†Ÿç¨³é‡' },
      { name: 'zh-CN-XiaohanNeural', displayName: 'æ™“æ¶µï¼ˆå¥³ï¼Œæ´»æ³¼ï¼‰', gender: 'å¥³', style: 'æ´»æ³¼' },
      { name: 'zh-CN-XiaomoNeural', displayName: 'æ™“å¢¨ï¼ˆå¥³ï¼Œæ¸©æŸ”ï¼‰', gender: 'å¥³', style: 'æ¸©æŸ”' },
      { name: 'zh-CN-XiaoxuanNeural', displayName: 'æ™“è±ï¼ˆå¥³ï¼Œæ¸©æŸ”ï¼‰', gender: 'å¥³', style: 'æ¸©æŸ”' },
      { name: 'zh-CN-XiaoruiNeural', displayName: 'æ™“ç¿ï¼ˆå¥³ï¼Œæˆç†Ÿï¼‰', gender: 'å¥³', style: 'æˆç†Ÿ' },
      { name: 'zh-CN-XiaoshuangNeural', displayName: 'æ™“åŒï¼ˆå¥³ï¼Œæ´»æ³¼ï¼‰', gender: 'å¥³', style: 'æ´»æ³¼' },
      { name: 'zh-CN-XiaoyanNeural', displayName: 'æ™“é¢œï¼ˆå¥³ï¼Œæ¸©æŸ”ï¼‰', gender: 'å¥³', style: 'æ¸©æŸ”' },
      { name: 'zh-CN-XiaoyouNeural', displayName: 'æ™“æ‚ ï¼ˆå¥³ï¼Œå¹´è½»ï¼‰', gender: 'å¥³', style: 'å¹´è½»' },
      { name: 'zh-CN-YunxiaNeural', displayName: 'äº‘å¤ï¼ˆç”·ï¼Œå¹´è½»ï¼‰', gender: 'ç”·', style: 'å¹´è½»' },
      { name: 'zh-CN-YunyeNeural', displayName: 'äº‘é‡ï¼ˆç”·ï¼Œæˆç†Ÿï¼‰', gender: 'ç”·', style: 'æˆç†Ÿ' },
    ];
  }

  /**
   * æ›´æ–°è¯­éŸ³é…ç½®
   */
  updateVoiceName(voiceName: string): void {
    this.config.voiceName = voiceName;
    // æ¸…é™¤ç¼“å­˜ï¼Œç¡®ä¿æ–°è¯­éŸ³ç«‹å³ç”Ÿæ•ˆ
    this.audioCache.clear().catch(err => {
    });
  }

  /**
   * ä¼°ç®—éŸ³é¢‘æ—¶é•¿
   */
  private estimateDuration(text: string, rate: number): number {
    // ç®€å•ä¼°ç®—ï¼šä¸­æ–‡å¤§çº¦æ¯ç§’ 3-4 ä¸ªå­—ï¼Œè‹±æ–‡å¤§çº¦æ¯ç§’ 4-5 ä¸ªå•è¯
    // æ ¹æ®è¯­é€Ÿè°ƒæ•´
    const isChinese = /[\u4e00-\u9fa5]/.test(text);
    const charsPerSecond = isChinese ? 3.5 * rate : 4.5 * rate;
    return text.length / charsPerSecond;
  }

  /**
   * ç”Ÿæˆç¼“å­˜é”®
   */
  private getCacheKey(text: string, lang: TTSLanguage, voiceConfig?: VoiceConfig): string {
    // è·å–å®é™…ä½¿ç”¨çš„è¯­éŸ³åç§°
    const languageCode = this.mapLanguage(lang);
    const actualVoiceName = this.config.voiceName || this.selectVoiceByLanguage(languageCode, voiceConfig?.gender);
    
    const parts = [
      'azure-speech',
      this.region,
      lang,
      actualVoiceName,  // åŒ…å«è¯­éŸ³åç§°ï¼Œç¡®ä¿åˆ‡æ¢è¯­éŸ³åä¸ä½¿ç”¨æ—§ç¼“å­˜
      text,
      voiceConfig?.gender || '',
      voiceConfig?.rate?.toString() || '',
      voiceConfig?.pitch?.toString() || '',
      voiceConfig?.volume?.toString() || '',
    ];
    return parts.join('|');
  }
}

